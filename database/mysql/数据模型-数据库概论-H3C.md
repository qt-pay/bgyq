# 数据模型-数据库概论-转



## 高可用

### binlog

https://database.51cto.com/art/202009/626540.htm

The server's binary log consists of files containing “events” that describe modifications to database contents. The server writes these files in binary format. To display their contents in text format, use the [**mysqlbinlog**](https://dev.mysql.com/doc/refman/8.0/en/mysqlbinlog.html) utility. 

binlog的主要作用是记录数据库中表的更改，它只记录改变数据的sql，不改变数据的sql不会写入，比如select语句一般不会被记录，因为它们不会对数据产生任何改动。

**binlog事件结构**

每个binlog事件由3个部分组成：

1.  通用头，包含binlog中所有事件具备的基本信息。
2.  提交头，对于不同类型的事件来说，提交头的内容也不尽相同
3.  事件体，存储事件的主要数据，同样对于不同类型事件也不同。

binlog轮换和清理



### relay-log

The relay log, like the binary log, consists of a set of numbered files containing events that describe database changes, and an index file that contains the names of all used relay log files. The default location for relay log files is the data directory.

The term “relay log file” generally denotes an individual numbered file containing database events. The term “relay log” collectively denotes the set of numbered relay log files plus the index file.

relay-log的结构和binlog非常相似，只不过它多了一个master.info和relay-log.info的文件。

**master.info**记录了上一次读取到master同步过来的binlog的位置，以及连接master和启动复制必须的所有信息。

**relay-log.info**记录了文件复制的进度，下一个事件从什么位置开始，由sql线程负责更新。

整个复制流程的过程大概是这：

1.  Master收到客户端请求语句，在语句结束之前向二进制日志写入一条记录，可能包含多个事件。
2.  此时，一个Slave连接到Master，Master的dump线程从binlog读取日志并发送到Slave的IO线程。
3.  IO线程从master.info读取到上一次写入的最后的位置。
4.  IO线程写入日志到relay-log中继日志，如果超过指定的relay-log大小，写入轮换事件，创建一个新的relay-log。
5.  更新master.info的最后位置
6.  SQL线程从relay-log.info读取进上一次读取的位置
7.  SQL线程读取日志事件
8.  在数据库中执行sql
9.  更新relay-log.info的最后位置
10.  Slave记录自己的binlog日志



### 异步复制

Asynchronous replication

MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后，会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主库如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整（主库事务执行完，从库没同步完）

### 全同步复制

Fully syncronous replication

指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。

因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。

### 半同步复制

Semi synchronous replication： 主库在应答客户端提交的事务前需要保证至少一个从库接收并写到relay log中。

介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log（中继日志）中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。

**如果主库突然宕机，数据还没有同步到从库里，数据就有可能丢失了；**

解决办法有两个机制，1.半同步复制，解决主数据库数据丢失问题 2. 并行复制，用来解决主从同步延时问题

半同步复制（semi-sync半同步复制）： 主库要求写数据的时候，记录binlog日志而且至少有一台从库把binlog日志同步成功了，并且从库返回一个ack，这里只是拉到从库本地的relay日志里，还没有完全同步，这个时候才会认为写操作成功了，否则写操作过来以后只是写好了binlog日志 还没有同步，就会认为是失败的或者说写操作还没有完成； 如果此时主库挂了，宕机了，就认为写操作是不成功的，不成功的话客户端可以感知到，重试一次，重试的时候从库已经切换成主库了，就可以保证写操作的时候还没有同步到从库，宕机导致数据丢失

### GTID模式（看）

https://gohalo.me/post/mysql-gtid.html

GTID 是一个已提交事务的编号，并且是一个全局唯一的编号，在 MySQL 中，GTID 实际上是由 UUID+TID 组成的。其中 UUID 是一个 MySQL 实例的唯一标识；TID 代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。

使用 GTID 功能具体可以归纳为以下两点：

- 可以确认事务最初是在哪个实例上提交的；
- 方便了 Replication 的 Failover 。

第一条显而易见，对于第二点稍微介绍下。

在 GTID 出现之前，在配置主备复制的时候，首先需要确认 event 在那个 binlog 文件，及其偏移量；假设有 A(Master)、B(Slave)、C(Slave) 三个实例，如果主库宕机后，需要通过 `CHANGE MASTER TO MASTER_HOST='xxx', MASTER_LOG_FILE='xxx', MASTER_LOG_POS=nnnn` 指向新库。

这里的难点在于，同一个事务在每台机器上所在的 binlog 文件名和偏移都不同，这也就意味着需要知道新主库的文件以及偏移量，对于有一个主库+多个备库的场景，如果主库宕机，那么需要手动从备库中选出最新的备库，升级为主，然后重新配置备库。

这就导致操作特别复杂，不方便实施，这也就是为什么需要 MHA、MMM 这样的管理工具。

之所以会出现上述的问题，主要是由于各个实例 binlog 中的 event 以及 event 顺序是一致的，但是 binlog+position 是不同的；而通过 GTID 则提供了对于事物的全局一致 ID，主备复制时，只需要知道这个 ID 即可。

另外，利用 GTID，MySQL 会记录那些事物已经执行，从而也就知道接下来要执行那些事务。当有了 GTID 之后，就显得非常的简单；因为同一事务的 GTID 在所有节点上的值一致，那么就可以直接根据 GTID 就可以完成 failover 操作。

写的真好，GTID 

gohalo.me/post/mysql-gtid.html

https://severalnines.com/resources/database-management-tutorials/mysql-replication-high-availability-tutorial

### MMM

MMM（Master-Master replication manager for MySQL）是一套支持双主故障切换和双主日常管理的脚本程序。

但是monitor单点，可以通过keepalived来实现高可用。

### Maxscale



### Galery

真正的multi-master 架构



## 事务

**事务是一系列操作的集合，打包成一个逻辑单元提供给应用层的抽象**。应用层可以认为事务是单一原子性操作，事务执行要么成功（全部操作都执行成功），要么失败（全部操作都没有执行）。不同事务并行执行不会互相影响

事务具有ACID特性

### Atomicity 原子性

原子性指不可分割的执行单元。事务的原子性指事务的所有操作要么全部成功执行，要么全部不执行，不存在部分执行的情况。

### Consistency一致性

一致性，这个词在不同的语境表示不同的含义：

- 在主从复制的场景中，一致性表示主从数据是否一致。
- 在 CAP 理论中，一致性是指线性一致性（Linearizability）。
- 在 ACID 的语境下，一致性表示数据库处于正确的状态。

数据库处于正确的状态，意味着事务从开始到结束需要遵守不变量，保证完整性约束不被破坏。**不变量其实是应用层层面的特性，需要应用层去保证的约束。**而 A（atomicity）、 I（isolation） 和 D（durability）是数据库层面的特性，应用层通过数据库提供的 A（atomicity）I（isolation）D（durability） 来保证 C（consistency）。

### Isolation隔离性

隔离性又称可串行性，指并行执行事务时事务彼此是互相隔离的，就如同串行执行事务的效果一样。在生产环境中，由于性能问题，并不是所有数据库都会支持最高级别可串行性的隔离级别，例如 Oracle 中实现的是快照隔离的隔离级别，比可串行性隔离级别稍弱一些。

### Durability 持久性

指数据库一旦修改成功就是永久的，即使系统故障也不会丢失。

### 并发事务带来的问题

在典型的应用程序中，多个事务并发运行，经常会操作相同的数据来完成各自的任务（多个用户对统一数据进行操作）。并发虽然是必须的，但可能会导致以下的问题。

- **脏读（Dirty read）:** 当一个事务正在访问数据并且对数据进行了修改，而这种修改还没有提交到数据库中，这时另外一个事务也访问了这个数据，然后使用了这个数据。因为这个数据是还没有提交的数据，那么另外一个事务读到的这个数据是“脏数据”，依据“脏数据”所做的操作可能是不正确的。
- **丢失修改（Lost to modify）:** 指在一个事务读取一个数据时，另外一个事务也访问了该数据，那么在第一个事务中修改了这个数据后，第二个事务也修改了这个数据。这样第一个事务内的修改结果就被丢失，因此称为丢失修改。 例如：事务1读取某表中的数据A=20，事务2也读取A=20，事务1修改A=A-1，事务2也修改A=A-1，最终结果A=19，事务1的修改被丢失。
- **不可重复读（Unrepeatableread）:** 指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
- **幻读（Phantom read）:** 幻读与不可重复读类似。它发生在一个事务（T1）读取了几行数据，接着另一个并发事务（T2）插入了一些数据时。在随后的查询中，第一个事务（T1）就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。

**不可重复度和幻读区别：**

不可重复读的重点是修改，幻读的重点在于新增或者删除。

例1（同样的条件, 你读取过的数据, 再次读取出来发现值不一样了 ）：事务1中的A先生读取自己的工资为 1000的操作还没完成，事务2中的B先生就修改了A的工资为2000，导 致A再读自己的工资时工资变为 2000；这就是不可重复读。

例2（同样的条件, 第1次和第2次读出来的记录数不一样 ）：假某工资单表中工资大于3000的有4人，事务1读取了所有工资大于3000的人，共查到4条记录，这时事务2 又插入了一条工资大于3000的记录，事务1再次读取时查到的记录就变为了5条，这样就导致了幻读。



## 事务隔离级别

多个并行执行的事务如果涉及到同一份数据的读写就容易出现 bug。**并行执行事务的正确性关键在于提供事务之间的隔离性。**最高级别的隔离性为可串行化，其保证了并行事务的执行和串行化执行的结果一致，但这同时也带来性能上的额外开销

**SQL 标准定义了四个隔离级别：**

- **READ-UNCOMMITTED(读取未提交)：** 最低的隔离级别，允许读取尚未提交的数据变更，**可能会导致脏读、幻读或不可重复读**。
- **READ-COMMITTED(读取已提交)：** 允许读取并发事务已经提交的数据，**可以阻止脏读，但是幻读或不可重复读仍有可能发生**。
- **REPEATABLE-READ(可重复读)：** 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，**可以阻止脏读和不可重复读，但幻读仍有可能发生**。
- **SERIALIZABLE(可串行化)：** 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，**该级别可以防止脏读、不可重复读以及幻读**。

Mysql官方给出的幻读解释是：只要在一个事务中，第二次select多出了row就算幻读。

a事务先select，b事务insert确实会加一个gap锁，但是如果b事务commit，这个gap锁就会释放（释放后a事务可以随意dml操作），a事务再select出来的结果在MVCC下还和***次select一样，接着a事务不加条件地update，这个update会作用在所有行上（包括b事务新加的），a事务再次select就会出现b事务中的新行，并且这个新行已经被update修改了，实测在RR级别下确实如此。

如果这样理解的话，Mysql的RR级别确实防不住幻读。



这里需要注意的是：与 SQL 标准不同的地方在于InnoDB 存储引擎在 **REPEATABLE-READ（可重读）** 事务隔离级别下，允许应用使用 Next-Key Lock 锁算法来避免幻读的产生。这与其他数据库系统(如 SQL Server)是不同的。所以说虽然 InnoDB 存储引擎的默认支持的隔离级别是 **REPEATABLE-READ（可重读）** ，但是可以通过应用加锁读（例如 `select * from table for update` 语句）来保证不会产生幻读，而这个加锁度使用到的机制就是 Next-Key Lock 锁算法。从而达到了 SQL 标准的 **SERIALIZABLE(可串行化)** 隔离级别。

因为隔离级别越低，事务请求的锁越少，所以大部分数据库系统的隔离级别都是**READ-COMMITTED(读取提交内容):**，但是你要知道的是InnoDB 存储引擎默认使用 **REPEATABLE-READ（可重读）** 并不会有任何性能损失。

InnoDB 存储引擎在 **分布式事务** 的情况下一般会用到**SERIALIZABLE(可串行化)** 隔离级别。

链接：https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB(%E5%9B%BE%E6%96%87%E8%AF%A6%E8%A7%A3).md

```bash
1.脏读
    一个事务读取到另一个事务的为提交数据
    设置A,B事务隔离级别为   Read uncommitted

    set session transaction isolation level  read uncommitted;

    1.在A事务中
        start transaction;
        update account set money=money-500 where name='aaa';
        update account set money=money+500 where name='bbb';

    2.在B事务中
        start transaction;
        select * from account;

    这时，B事务读取时，会发现，钱已经汇完。那么就出现了脏读。

    当A事务提交前，执行rollback，在commit， B事务在查询，就会发现，钱恢复成原样
    也出现了两次查询结果不一致问题，出现了不可重复读.

2.解决脏读问题
    将事务的隔离级别设置为 read committed来解决脏读

    设置A,B事务隔离级别为   Read committed

    set session transaction isolation level  read committed;

    1.在A事务中
        start transaction;
        update account set money=money-500 where name='aaa';
        update account set money=money+500 where name='bbb';

    2.在B事务中
        start transaction;
        select * from account;

    这时B事务中，读取信息时，是不能读到A事务未提交的数据的，也就解决了脏读。

    让A事务，提交数据 commit;

    这时，在查询，这次结果与上一次查询结果又不一样了，还存在不可重复读。

3.解决不可重复读
    将事务的隔离级别设置为Repeatable read来解决不可重复读。
    设置A,B事务隔离级别为   Repeatable read;
    set session transaction isolation level  Repeatable read;

    1.在A事务中
            start transaction;
            update account set money=money-500 where name='aaa';
            update account set money=money+500 where name='bbb';

    2.在B事务中
            start transaction;
            select * from account;
    当A事务提交后commit;B事务在查询，与上次查询结果一致，解决了不可重复读。

4.设置事务隔离级别Serializable ,它可以解决所有问题
    set session transaction isolation level Serializable;

    如果设置成这种隔离级别，那么会出现锁表。也就是说，一个事务在对表进行操作时，
    其它事务操作不了。
```

end

## 分库分表

如果说读写分离实现了数据库**读能力的水平扩展**，那么分库分表就是实现了**写能力的水平扩展**。

主要是sharding-map，这个词原来叫做分布式事务中间件。

**分库分表就是为了解决由于数据量过大而导致数据库性能降低的问题，将原来独立的数据库拆分成若干数据库组成 ，将数据大表拆分成若干数据表组成，使得单一数据库、单一数据表的数据量变小，从而达到提升数据库性能的目的。**

map-reduce？

关系型数据库通常采用**分库分表**的方式来应对海量数据和高并发请求：

- **读写分离**：一主多从，主负责写，从允许读。主从保持数据同步。
- **垂直分库**：将不同模块的数据拆分到不同的数据库中。
- **垂直分表**：按列拆分，分离不常使用的字段。
- **水平分库**：将表的数据按规则划分到不同的数据库。
- **水平分表**：将表的数据按规则划分到多张表中。

水平分库分表后难以处理跨库 join/group by/order by 等操作，且跨库涉及的事务处理将带来高昂的成本（后续介绍分布式事务会讲解 MySQL XA 分布式事务）。

NoSQL 只保证最终一致性，扩展性强。NoSQL 和关系型数据库**本质上是 BASE 模型和 ACID 模型的区别**。BASE 即**基本可用（Basically Available）**、**软状态（Soft State）**、**最终一致性（Eventually Consistency）**，由 Dan Pritchett 在 [BASE: An Acid Alternative](https://dl.acm.org/citation.cfm?id=1394128)中提出，其核心思想是：

> Trading some consistency for availability can lead to dramatic improvements in scalability.

即**牺牲部分一致性可以显著提升系统的扩展性**，感兴趣可以阅读本文结尾的附录章节。

**CAP 定理**指出，分布式计算机系统**不可能同时满足一致性（Consistency）、可用性（Availability）和分区容错性（Partition Tolerance）。**

### 垂直分库

将原有的SELLER_DB(卖家库)，分为PRODUCT_DB(商品库)和STORE_DB(店铺库)，并把这两个库分散到不同服务器。这样可以避免当个数据库服务器压力过大。代码写数据的时候连接不同的服务器地址就行了。

### 水平分库

这个hash怎么实现的呢，需要看个代码了

经过**垂直分库**后，数据库性能问题得到一定程度的解决，但是随着业务量的增长，PRODUCT_DB(商品库)单库存储数据已经超出预估。粗略估计，目前有8w店铺，每个店铺平均150个不同规格的商品，再算上增长，那商品数量得往1500w+上预估，并且PRODUCT_DB(商品库)属于访问非常频繁的资源，单台服务器已经无法支撑。此时该如何优化？

 再次分库？但是从业务角度分析，目前情况已经无法再次垂直分库。

 尝试水平分库，将店铺ID为单数的和店铺ID为双数的商品信息分别放在两个库中。

也就是说，要操作某条数据，先分析这条数据所属的店铺ID。如果店铺ID为双数，将此操作映射至RRODUCT_DB1(商品库1)；如果店铺ID为单数，将操作映射至RRODUCT_DB2(商品库2)。此操作要访问数据库名称的表达式为**RRODUCT_DB[店铺ID%2 + 1]** 。

 **水平分库**是把同一个表的数据按一定规则拆到不同的数据库中，每个库可以放在不同的服务器上。

### 垂直分表

栗子，原商品表，包含了商品基本信息和商品描述信息。但两种数据的特性不一样，因此他考虑将商品信息表拆分如下：

 将访问频次低的商品描述信息单独存放在一张表中，访问频次较高的商品基本信息单独放在一张表中。

这样就不会由于，商品详情字段存储占用空间较大，访问单个数据IO时间较长，拖累整体的访问时间。

### 水平分表

水平分库的思路类似，不过这次操作的目标是表，商品信息及商品描述被分成了两套表。如果商品ID为双数，将此操作映射至商品信息1表；如果商品ID为单数，将操作映射至商品信息2表。此操作要访问表名称的表达式为**商品信息[商品ID%2 + 1]** 。

### 热点数据缓存

针对热点商品这些类型的数据，要考虑到访问量比较大，大家首先想到的是缓存，上redis缓存，这点肯定没有错。先从缓存中获取，没有再到DB获取，并保存到缓存中。但有个问题会产生，热点数据的访问会比较大，如果缓存一旦失效，所有请求同一时刻，会打到DB上面，DB肯定会崩溃。那怎么办呢？

缓存一旦失效，如何重新构建缓存？**首先需要避免失效那一刻大量请求同时去重新构建缓存**。因为重新构建缓存，需要到数据库DB中获取数据，那一个时刻的所有请求到DB上面。

方案有两种，第一个方案是把请求进入队列中。还有一个方案就比较简单，**利用**分布式锁，只允许一个请求线程去访问DB，其他请求阻塞，这样就避免了很多请求打到DB上。

热点数据，需要人工预测。


链接：https://juejin.cn/post/6844903856011231239



其实使用缓存集群的时候，最怕的就是热key、大value这两种情况，那啥叫热key大value呢？

简单来说，热key，就是你的缓存集群中的某个key瞬间被数万甚至十万的并发请求打爆。

大value，就是你的某个key对应的value可能有GB级的大小，导致查询value的时候导致网络相关的故障问题

#### 大 value

其实无论是大 value，还是大 key，都是应该极力避免的。

主要出于两个原因：

1. 大 value 会造成 redis 传输的抖动
2. 较大的数据传输消耗网络 io。

#### 热key

好，所谓的热点缓存问题是什么意思呢？

很简单，就是**突然因为莫名的原因，出现大量的用户访问同一条缓存数据。**

举个例子，某个明星突然宣布跟某某结婚，这个时候是不是会引发可能短时间内每秒都是数十万的用户去查看这个明星跟某某结婚的那条新闻？

那么假设那条新闻就是一个缓存，然后对应就是一个缓存key，就存在一台缓存机器上，此时瞬时假设有20万请求奔向那一台机器上的一个key。

结果此时，每秒突然奔过来20万请求到这台机器上，会怎么样？

很简单，上面图里那台被20万请求指向的缓存机器会过度操劳而宕机的。

那么如果缓存集群开始出现机器的宕机，此时会如何？

接着，读请求发现读不到数据，会从数据库里提取原始数据，然后放入剩余的其他缓存机器里去。但是接踵而来的每秒20万请求，会再次压垮其他的缓存机器。 以此类推，最终导致缓存集群全盘崩溃，引发系统整体宕机。

ps: 简而言之，整个服务器直接瘫痪。

#### 缓存集群的作用

缓存集群的并发能力是很强的，而且读缓存的性能是很高的。

举个例子，假设你每秒有2万请求，但是其中90%都是读请求，那么每秒1.8万请求都是在读一些不太变化的数据，而不是写数据。

那此时你把数据都放在数据库里，然后每秒发送2万请求到数据库上读写数据，你觉得合适吗？

当然不太合适了，如果你要用数据库承载每秒2万请求的话，那么不好意思，你很可能就得搞分库分表 + 读写分离。

比如你得分3个主库，承载每秒2000的写入请求，然后每个主库挂3个从库，一共9个从库承载每秒1.8万的读请求。

这样的话，你可能就需要一共是12台高配置的数据库服务器，这是很耗费钱的，成本非常高，而且很不合适。

所以，此时你完全就可以把平时不太变化的数据放在缓存集群里，缓存集群可以采用2主2从，主节点用来写入缓存，从节点用来读缓存。

以缓存集群的性能，2个从节点完全可以用来承载每秒1.8万的大量读了，然后3个数据库主库就是承载每秒2000的写请求和少量其他读请求就可以了。

大家看看下面的图，你耗费的机器瞬间变成了4台缓存机器 + 3台数据库机器 = 7台机器，是不是比之前的12台机器减少了很大的资源开销？

没错，缓存其实在系统架构里是非常重要的组成部分。

很多时候，对于那些很少变化但是大量高并发读的数据，通过缓存集群来抗高并发读，是非常合适的。





### 最佳实践

垂直分表：可以把一个宽表的字段按访问频次、是否是大字段的原则拆分为多个表，这样既能使业务清晰，还能提升部分性能。拆分后，尽量从业务角度避免联查，否则性能方面将得不偿失。

垂直分库：可以把多个表按业务耦合松紧归类，分别存放在不同的库，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能，同时能提高整体架构的业务清晰度，不同的业务库可根据自身情况定制优化方案。但是它需要解决跨库带来的所有复杂问题。

水平分库：可以把一个表的数据(按数据行)分到多个不同的库，每个库只有这个表的部分数据，这些库可以分布在不同服务器，从而使访问压力被多服务器负载，大大提升性能。它不仅需要解决跨库带来的所有复杂问题，还要解决数据路由的问题(数据路由问题后边介绍)。

水平分表：可以把一个表的数据(按数据行)分到多个同一个数据库的多张表中，每个表只有这个表的部分数据，这样做能小幅提升性能**，它仅仅作为水平分库的一个补充优化**。

一般来说，在系统设计阶段就应该根据业务耦合松紧来确定垂直分库，垂直分表方案，在数据量及访问压力不是特别大的情况，首先考虑缓存、读写分离、索引技术等方案。若数据量极大，且持续增长，再考虑水平分库水平分表方案。

### 数据库连接池

[MySQL](https://cloud.tencent.com/product/cdb?from=10680)连接池是一个很好的设计，通过将大量短连接转化为少量的长连接，从而提高整个系统的吞吐率。

数据库连接池负责分配、管理和释放数据库连接，它允许应用程序重复使用一个现有的数据库连接，而不是再重新建立一个。

连接池的工作原理主要由三部分组成，分别为

1. 连接池的建立
2. 连接池中连接的使用管理
3. 连接池的关闭

使用连接池时，要配置一下参数

1. 最小连接数：是连接池一直保持的数据库连接,所以如果应用程序对数据库连接的使用量不大,将会有大量的数据库连接资源被浪费.
2. 最大连接数：是连接池能申请的最大连接数,如果数据库连接请求超过次数,后面的数据库连接请求将被加入到等待队列中,这会影响以后的数据库操作
3. 最大空闲时间
4. 获取连接超时时间
5. 超时重试连接次数





不使用数据库连接池的步骤：

* TCP建立连接的三次握手
*  MySQL认证的三次握手
*  真正的SQL执行
*  MySQL的关闭
*  TCP的四次握手关闭
*  可以看到，为了执行一条SQL，却多了非常多我们不关心的网络交互。

优点：实现简单

缺点：

* 网络IO较多
*  数据库的负载较高
*  响应时间较长及QPS较低
*  应用频繁的创建连接和关闭连接，导致临时对象较多，GC频繁
*  在关闭连接后，会出现大量TIME_WAIT 的TCP状态（在2个MSL之后关闭）

使用数据库连接池的步骤：

第一次访问的时候，需要建立连接。 但是之后的访问，均会复用之前创建的连接，直接执行SQL语句。

优点：

1. 较少了网络开销
2. 系统的性能会有一个实质的提升
3. 没了麻烦的TIME_WAIT状态

以Java为例...

类似的，在执行JDBC的增删改查的操作时，如果每一次操作都来一次打开连接，操作，关闭连接，那么创建和销毁JDBC连接的开销就太大了。为了避免频繁地创建和销毁JDBC连接，我们可以通过连接池（Connection Pool）复用已经创建好的连接。

JDBC连接池有一个标准的接口`javax.sql.DataSource`，注意这个类位于Java标准库中，但仅仅是接口。要使用JDBC连接池，我们必须选择一个JDBC连接池的实现。常用的JDBC连接池有：

- HikariCP
- C3P0
- BoneCP
- Druid

目前使用最广泛的是HikariCP。



### ORM

**对象关系映射（Object Relational Mapping，简称ORM，或O/RM，或O/R mapping）**

面向对象是从软件工程基本原则（如耦合、聚合、封装）的基础上发展起来的，而关系数据库则是从数学理论发展而来的（关系型数据库不是面向对象的），两套理论存在显著的区别。

而面向对象的编程思想是软件开发的一大趋势，而关系数据库也是目前的必然存在，两种理论的差别的不匹配，造就了ORM。





Golang： https://github.com/jmoiron/sqlx

Java：

JDBC将应用程序开发者与底层数据库驱动程序进行解耦，作为中间层承上启下

而ORM是插入在应用程序与JDBCAPI之间的一个中间层，JDBC并不能很好地支持面向对象的程序设计

ORM解决了这个问题，通过JDBC将字段高效的与对象进行映射

应用程序开发人员不再需要直接与JDBC API进行打交道了，可以使用更加便利的ORM工具，提高开发效率

**所以ORM是干什么的？**

**ORM用于完成Java对象与关系型数据库的映射，是JDBC的一层封装，提高了易用性。**

**简言之，ORM工具就是JDBC的封装，简化了JDBC的使用，完成关系型数据库中数据与Java对象的映射。**

## 数据库连接池+事务

连接池中不同连接处理+同一个事务的问题。



https://cloud.tencent.com/developer/article/1005299

https://cloud.tencent.com/developer/article/1005302?from=article.detail.1005299

## 数据库中间件

### DAL

Data Access Layer

Qihoo 360的Atlas

Mysql官方的：Mysql router 和 Mysql Proxy

美团：DBProxy

https://developer.aliyun.com/article/706766

### Grant

授权认证是几元组，用户名，连接地址，等？

## 索引

## 锁

## 高可用

https://www.modb.pro/db/15033

#### MHA

https://segmentfault.com/a/1190000021100914

#### Maxscale

http://www.ttlsa.com/mysql/maxscale-install-read-write-split/

Maxscale默认只提供读的高可用性，要实现写的高可用性，可以使用两种途径：

1.需要使用Multi-MasterMonitor监控模块，不同于上文使用的mysqlmon模块，该模块是通过read_only参数来选举Master和Slave,结合脚本可以实现在Master fail的时候，取消slave的read_only属性，将slave提升为Master

2.使用高可用软件MMM

### Galery

https://blog.csdn.net/weixin_42467457/article/details/115849074 

# DRDS

业务增长带来的数据量膨胀，存储、并发、QPS增长等都会导致 RDS性能瓶颈。迁移到DRDS进行分库分表是一个很好的选择。

各大产品：

阿里系：OceanBase(蚂蚁金服数据库团队),PolarDB-X(融合了阿里云团队的PolarDB和阿里集团数据库团队X-DB)

H3C：

## 分布式事务

由于分库分表导致的分布式事务。

详见 数据库中间件

分库分表的挑战主要体现在4个方面：基本的数据库增删改功能，分布式id，分布式事务，动态扩容，下面逐一进行讲述。 

**挑战1：基本的数据库增删改功能**  

例如1号记录插入user1表，2号记录插入user2表，3号记录插入user3表，4号记录插入user0表，以此类推。sql如下所示：

```
insert into user(id,name) values (1,”tianshouzhi”),(2,”huhuamin”), (3,”wanghanao”),(4,”luyang”)
```

 这样的sql明显是无法执行的，因为我们已经对库和表进行了拆分,这种sql语法只能操作mysql的单个库和单个表。所以必须将sql改成4条如下所示，然后分别到每个库上去执行。

需要以下来实现（map-reduce：通过分散计算来分析大量数据）：

  **sql解析：**首先对sql进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4

  **sql路由：**sql路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。

  **sql改写：**因为一条记录只能插入到一个库中，而上述批量插入的语法将会在每个库中都插入四条记录，明显是不合适的，因此需要对sql进行改写，每个表只插入一条记录。

  **sql执行：**一条sql经过改写后变成了多条sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行。

  **结果集合并：**每个sql执行之后，都会有一个执行结果，我们需要对分库分表的结果集进行合并，从而得到一个完整的结果。

 难--

**挑战2：分布式id**

在分库分表后，我们不能再使用mysql的自增主键。因为在插入记录的时候，不同的库生成的记录的自增id可能会出现冲突。因此需要有一个全局的id生成器。目前分布式id有很多种方案，其中一个比较轻量级的方案是twitter的snowflake算法。

**挑战3：分布式事务**

分布式事务是分库分表绕不过去的一个坎，因为涉及到了同时更新多个分片数据。例如上面的批量插入记录到四个不同的库，如何保证要么同时成功，要么同时失败。关于分布式事务，mysql支持XA事务，但是效率较低。柔性事务是目前比较主流的方案，柔性事务包括：最大努力通知型、可靠消息最终一致性方案以及TCC两阶段提交。但是无论XA事务还是柔性事务，实现起来都是非常复杂的。

最复杂--

**挑战4：动态扩容**

动态扩容指的是增加分库分表的数量。例如原来的user表拆分到2个库的四张表上。现在我们希望将分库的数量变为4个，分表的数量变为8个。这种情况下一般要伴随着数据迁移。例如在4张表的情况下，id为7的记录，7%4=3，因此这条记录位于user3这张表上。但是现在分表的数量变为了8个，而7%8=0，而user0这张表上根本就没有id=7的这条记录，因此如果不进行数据迁移的话，就会出现记录找不到的情况。

## 分布式数据库中间件

shardingsphere 真不错-

典型的数据库中间件设计方案有2种：proxy、smart-client。

* Proxy

  业务代码--> 框架 --> ORM --> 数据库连接池/驱动 --> Proxy --> multi-databases

  Proxy代理N个dbs，比较透明，开发人员可以直接连接Proxy，把它当作数据库。

  proxy需要实现被代理的数据库server端的通信协议，实现难度较大，且通常proxy只支持一种数据库mysql...

  Proxyz作为代理要保证它的高可用和不同client的资源隔离性。

* Smart-client

  业务代码--> 框架 --> ORM --> Smart Client -->数据库连接池/驱动  --> multi-databases

  业务代码需要进行一些改造，引入支持读写分离或者分库分表的功能的sdk，这个就是我们的smart-client。通常smart-client是在连接池或者driver的基础上进行了一层封装，smart-client内部与不同的库建立连接。应用程序产生的sql交给smart-client进行处理，其内部对sql进行必要的操作，例如在读写分离情况下，选择走从库还是主库；在分库分表的情况下，进行sql解析、sql改写等操作，然后路由到不同的分库，将得到的结果进行合并，返回给应用。

  这个实现简单，因为smart-client集成了原有的各个db driver的实现。

  此外，smart-client也天然去中心化。smart-client的方式，由于本身以sdk的方式，被应用直接引入，随着应用部署到不同的节点上，且直连数据库，中间不需要有代理层。

  缺点：

  既然是SDK，那么smart-client就受到语言的限制，此外smart-client的升级比较困难，因为它和代码绑定--没有独立的Proxy升级方便。

**proxy实现**

目前的已有的实现方案有：

- 阿里巴巴开源的cobar
- 阿里云上的drds
- mycat团队在cobar基础上开发的mycat
- mysql官方提供的mysql-proxy
- 奇虎360在mysql-proxy基础开发的atlas(只支持分表，不支持分库)
- 当当网开源的sharing-sphere

目前除了mycat、sharing-sphere，其他几个开源项目基本已经没有维护，sharing-sphere前一段时间已经进去了Apache 软件基金会孵化器。

**smart-client实现**

目前的实现方案有：

- 阿里巴巴开源的tddl，已很久没维护
- 大众点评开源的zebra，大众点评的zebra开源版本代码已经很久没有更新，不过最近美团上市，重新开源大量内部新的功能特性，并计划长期维持。
- 当当网开源的sharding-jdbc，目前算是做的比较好的，文档资料比较全。和sharding-sphere一起进入了Apache孵化器。
- 蚂蚁金服的zal
- 等等

Java：https://shardingsphere.apache.org/document/legacy/4.x/document/cn/manual/sharding-jdbc/#%E7%AE%80%E4%BB%8B

分布式数据库中间件（Distributed Database Middleware，简称DDM），使用云数据库（RDS）作为存储引擎，具备自动部署、分库分表、弹性伸缩、高可用等全生命周期运维管控能力。专注于解决数据库分布式扩展问题，突破了传统数据库的容量和性能瓶颈，实现海量数据高并发访问。

Apache基金会：ShardingSphere

参考阿里的文档：https://www.alibabacloud.com/help/zh/doc-detail/164359.htm

从RDS迁移到DRDS可能需要考虑如下问题：

- DRDS规格如何选取？
- DRDS下挂载的RDS规格如何选取？
- RDS中的单表迁移到DRDS后，如何拆分？包括分表数及拆分键的选取？
  - 拆分推荐，包括：
    - 源库中各个表是否拆分，选取哪个字段为拆分键。
    - 源库中各个表导入到DRDS时的建表语句，并提供对所有建表语句的导出功能。
- 如何快速建库，建表？
- 如何快速将数据从RDS导入到DRDS？



